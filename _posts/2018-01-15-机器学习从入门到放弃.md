机器学习从入门到放弃
================
## [0. 为什么要了解机器学习](#0)
## [1. 什么是机器学习](#1)
## [2. 机器学习的应用](#2)
## [3. 机器学习算法](#3)
## [4. 如何入门机器学习](#4)

<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<h2 id="0">为什么要了解机器学习</h2>

### 身边机器学习

- 电商的商品推荐
- 音乐推荐
- 搜索引擎排名
- iPhone人脸解锁
- 垃圾邮件过滤
- 机器翻译软件

### AI(人工智能)

#### AlphGo 
![](/images/AlphaGo-Lee-Sedol-game-3-game-over.jpg)
#### 自动驾驶(Google 无人车) 
![](/images/Google_self_driving_car_at_the_Googleplex.jpg)
#### 对话机器人(Siri) 
![](/images/New-Siri-iOS-11-Icon-484x320.jpg)

#### [机器翻译(Google 统计机器翻译->神经机器翻译)](https://translate.google.com.hk/?hl=zh-CN&tab=wT#auto/zh-CN/Once%20you%20have%20written%20your%20seeder%20classes%2C%20you%20may%20use%20the%20db%3Aseed%20Artisan%20command%20to%20seed%20your%20database.%20By%20default%2C%20the%20db%3Aseed%20command%20runs%20the%20DatabaseSeeder%20class%2C%20which%20may%20be%20used%20to%20call%20other%20seed%20classes.%20However%2C%20you%20may%20use%20the%20--class%20option%20to%20specify%20a%20specific%20seeder%20class%20to%20run%20individually%3A)
...

### 机器学习和AI的关系
![机器学习和AI的关系](/images/v2-4515dd3be22d73d16a20603bd8f3bbfc_hd.jpg)

- 理解最新技术背后的原理
- 学习机器学习解决问题的思维模式

# SECTION END

<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<h2 id="1">什么是机器学习</h2>


- ### 定义:

> 对于某类**任务** T 和**性能度量** P，如果一个计算机程序在 T 上以 P 衡量的 性能随着**经验** E 而自我完善，那么我们称这个计算机程序在从经验 E 学习。

* #### AlphGo： AlphGo 是下围棋的程序：通过不断和自己对弈提高棋力。

    > - 任务：下围棋。
      - 性能：胜率，即比赛中击败对手的百分比。
      - 经验：和自己对弈。

* #### 医疗诊断：

    > - 任务：判断病人是否患有某种病。
      - 性能：诊断的准确率。
      - 经验：人类医生记录的病例。

- ### 分类：根据经验的来源或类型

    - #### 监督学习--直接经验 (有标签，学习难度简单，速度快)
        - 医疗诊断任务：医学影像（特征-像素）->标签-是否患有某某病
        ![医学影像](http://www.aiepoch.net/wp-content/uploads/2017/05/2017050412445173.jpg)
        - 房价预测任务：房产数据（特征-位置、大小、房间数量、楼层、开发商）-> 标签-房价（xxxxx元/$M^2$）
    - #### 无监督学习--没有标签。
        - 任务：聚类-例子：新闻分类。
        - 密度估计：异常检测
    - #### 强化学习(反馈学习)--非即时标签
        - 例子：围棋程序：给定局面，监督学习直接给出走法，强化学习在棋局结束时给出胜负。

[机器学习的应用](#2)

<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />

<h2 id="2">机器学习的应用</h2>

- 图像识别
    - 如人脸识别，图像分类,对象跟踪
    - 最先进的是CNN技术
    - ILSVRC(ImageNet Large Scale Visual Recognition Competition)达到高峰
      
      2012年CNN 实现 Top 5 误差率 15.4% ，当时的次优项误差率为 26.2%
<table> 
 <tbody> 
  <tr> 
   <th><span>模型</span></th> 
   <th><span>AlexNet</span></th> 
   <th><span>ZF Net</span></th> 
   <th><p><span>GoogLeNet</span></p></th> 
   <th><span>ResNet</span></th> 
  </tr> 
  <tr> 
   <td><span>时间（年）</span></td> 
   <td><span>2012</span></td> 
   <td><span>2013</span></td> 
   <td><span>2014</span></td> 
   <td><span>2015 </span></td> 
  </tr> 
  <tr> 
   <td><span>层数（层）</span></td> 
   <td><span>8</span></td> 
   <td><span>8</span></td> 
   <td><span>22</span></td> 
   <td><span>152</span></td> 
  </tr> 
  <tr> 
   <td><span>Top 5 错误率</span></td> 
   <td><span>15.4%</span></td> 
   <td><span>11.2%</span></td> 
   <td><span>6.7%</span></td> 
   <td><span>3.57%</span></td> 
  </tr> 
  <tr> 
   <td><span>数据增强</span></td> 
   <td><span>√</span></td> 
   <td><span>√</span></td> 
   <td><span>√</span></td> 
   <td><span>√</span></td> 
  </tr> 
  <tr> 
   <td><span>Dropout</span></td> 
   <td><span>√</span></td> 
   <td><span>√</span></td> 
   <td></td> 
   <td></td> 
  </tr> 
  <tr> 
   <td><span>批量归一化</span></td> 
   <td></td> 
   <td></td> 
   <td></td> 
   <td><span>√</span></td> 
  </tr> 
 </tbody> 
</table>
      CUImage（商汤和港中文），Trimps-Soushen（公安部三所），CUvideo（商汤和港中文），HikVision（海康威视），SenseCUSceneParsing（商汤和香港城市大学），NUIST（南京信息工程大学）包揽了各个项目的冠军。
      
- 自然语言处理
    - 语音识别
    - 如Google翻译
    - 语音合成
    - 自动摘要
    - 对话机器人
- 推荐系统
- 医疗诊断
- 异常检测
- 游戏AI


[3. 机器学习算法](#3)

<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<h2 id="3">机器学习算法</h2>

- ### 线性回归 (回归)
    - 房价预测的例子
    - 现有数据：特征-位置、大小、房间数量、楼层、开发商、年份
<table> 
 <tbody> 
  <tr> 
   <th><span>行号</span></th> 
   <th><span>距离市中心(KM)</span></th> 
   <th><span>大小($m^2$)</span></th> 
   <th><p><span>房间数量</span></p></th> 
   <th><span>年份</span></th> 
   <th><span>价格(万)</span></th> 
  </tr> 
  <tr> 
   <td><span>1</span></td> 
   <td><span>20</span></td> 
   <td><span>80</span></td> 
   <td><span>2</span></td> 
   <td><span>2015 </span></td> 
   <td><span>100 </span></td> 
  </tr> 
  <tr> 
   <td><span>2</span></td> 
   <td><span>8</span></td> 
   <td><span>89</span></td> 
   <td><span>2</span></td> 
   <td><span>2016</span></td> 
   <td><span>150</span></td> 
  </tr> 
  <tr> 
   <td><span>3</span></td> 
   <td><span>15</span></td> 
   <td><span>112</span></td> 
   <td><span>3</span></td> 
   <td><span>2017</span></td> 
   <td><span>200</span></td> 
  </tr> 
  <tr> 
   <td><span>4</span></td> 
   <td><span>1</span></td> 
   <td><span>100</span></td> 
   <td><span>3</span></td> 
   <td><span>2018</span></td> 
   <td><span>218</span></td> 
  </tr> 
  <tr> 
   <td><span>5</span></td> 
   <td><span>9</span></td> 
   <td><span>100</span></td> 
   <td>3</td> 
   <td>2014</td> 
   <td>180</td> 
  </tr> 
    <tr> 
   <td><span>...</span></td> 
   <td>...</td> 
   <td>...</td> 
   <td>...</td> 
   <td>...</td> 
   <td>...</td> 
  </tr> 
 </tbody> 
</table>

    > 模型: $ y= w_1 * x_1 + w_2 * x_2 + w_3 * x_3 + ...$

    > 性能度量：最小平方误差 $e = \sum_1^n{[y^i-(w_1 * x_1^i + w_2 * x_2^i + w_3 * x_3^i + ...)]^2}$

    > 优化算法解出 $w_i$

![拟合图](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Linear_least_squares.svg/220px-Linear_least_squares.svg.png)

- ### Logistic 回归 (分类)
    - [泰坦尼克号挑战](https://www.kaggle.com/c/titanic)
<table>
<tbody>
<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>
<tr>
<td>survival</td>
<td>Survival</td>
<td>0 = No, 1 = Yes</td>
</tr>
<tr>
<td>pclass</td>
<td>Ticket class</td>
<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>
</tr>
<tr>
<td>sex</td>
<td>Sex</td>
<td></td>
</tr>
<tr>
<td>Age</td>
<td>Age in years</td>
<td></td>
</tr>
<tr>
<td>sibsp</td>
<td># of siblings / spouses aboard the Titanic</td>
<td></td>
</tr>
<tr>
<td>parch</td>
<td># of parents / children aboard the Titanic</td>
<td></td>
</tr>
<tr>
<td>ticket</td>
<td>Ticket number</td>
<td></td>
</tr>
<tr>
<td>fare</td>
<td>Passenger fare</td>
<td></td>
</tr>
<tr>
<td>cabin</td>
<td>Cabin number</td>
<td></td>
</tr>
<tr>
<td>embarked</td>
<td>Port of Embarkation</td>
<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>
</tr>
</tbody>
</table>

    > 假设:

    > $\sigma = \frac{1}{1+e^{-t}}; t=w_1 * x_1 + w_2 * x_2 + ...$

    > 性能度量:

    > $L(w) = P(y|x;w) = \prod^N_{n=1}P(y^{(n)}|x^{(n)};w)$

    ![Logistic function](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png)

- ### 朴素贝叶斯
    - 问题：![桶球模型](/images/Screenshot_from_2018-02-01_21-35-24.png)
    - 贝叶斯公式 

    ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/904d9aa8abba54d5a1aa3546046a9d21eff45b61)

    ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/4fd7f9a529ccc27ad6aac91297c81f963e69c3ed)

    - #### 垃圾邮件过滤
        - 特征：词袋模型
        - 独立性假设： $P(单词_1,单词_2,...|垃圾邮件) = P(单词_1|垃圾邮件) * P(单词_2|垃圾邮件) * ...$
        - 计算：
        $P(垃圾邮件|单词_1,单词_2,...) = \frac{P(单词_1,单词_2,...|垃圾邮件) * P(垃圾邮件)}{P(单词_1,单词_2,...)}$
        $=\frac{P(单词_1|垃圾邮件) * P(单词_2|垃圾邮件) * ... * P(垃圾邮件)}{P(单词_1,单词_2,...|垃圾邮件) * P(垃圾邮件) + P(单词_1,单词_2,...|非垃圾邮件) * P(非垃圾邮件)}$


- ### 决策树
![相亲决策树](https://images.cnblogs.com/cnblogs_com/leoo2sk/WindowsLiveWriter/34d255f282ae_B984/1_3.png)

    - ####[用随机森林探测shadowsocks流量](https://xindoo.me/article/1184)

- ### 神经网络
    - #### 感知机

    ![感知机](https://upload.wikimedia.org/wikipedia/commons/9/97/Ncell.png)

    - #### 多模型

    ![多模型](https://upload.wikimedia.org/wikipedia/commons/a/a8/SingleLayerNeuralNetwork_english.png)

    - #### 神经网络

    ![神经网络](http://www.ruanyifeng.com/blogimg/asset/2017/bg2017071201.jpg)

    - #### 图像识别，使用CNN(卷积神经网络)
        - 特征：像素
        - 与一般ANN不同之处：卷积操作
        - ![](http://img.my.csdn.net/uploads/201304/10/1365562155_9356.jpg)
    
- ### 高斯密度估计
     - 高斯分布

    ![高斯分布](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/700px-Standard_deviation_diagram.svg.png)

    - 异常检测
        - 服务器运行异常
            - 特征：网络流量/CPU利用率
            - 定时收集特征，建立其高斯分布
            - 决定临界值


[4. 如何入门机器学习](#4)
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />

<h2 id="4">如何入门机器学习</h2>

- ### 找到你的定位
    - 研究型(give up)
    - 应用型
- ### 资源 
    - 在线课程：[吴恩达在coursera 的课程](https://www.coursera.org/learn/machine-learning/)
    - 数据分析入门读物：[python machine learning ](http://books.tarsoit.com/Python%20Machine%20Learning.pdf)
    - 进阶读物：
        - The Elements of Statistical Learning 

        ![The Elements of Statistical Learning](https://images-na.ssl-images-amazon.com/images/I/41aQrQaPseL._AC_US436_QL65_.jpg)

        - Pattern Recognition and Machine Learning 

        ![Pattern Recognition and Machine Learning](https://images-na.ssl-images-amazon.com/images/I/61FKyOeM7KL._AC_US436_FMwebp_QL65_.jpg)

        - 概率图模型:原理与技术
        ![概率图模型:原理与技术](https://images-cn.ssl-images-amazon.com/images/I/514Ox3EsuNL._AA218_.jpg)

- ### 用 kaggle 锻炼自己的能力
    - 实践学习到的算法
    - 学习别人的特征工程
- ### 尝试自己实现机器学习算法
    - 线性回归
    - Logistic 回归



<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
